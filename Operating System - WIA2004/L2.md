# Early Memory Management Systems

### Introduction
- Management of main memory is critical.
- The performance of the entire system has been directly dependent on two things:
	- How much memory is available
	- How it is optimization while jobs are being processed.
- This chapter introduces:
	- The memory manager (RAM)
	- Core memory (primary storage)
- This chapter introduces:
	- Four types of memory allocation schemes
		- Single-user systems
		- Fixed partitions
		- Dynamic partitions
		- Relocatable dynamic partitions
	- These early memory management schemes are seldom used by today’s OSs but are important to study because each one introduced fundamental concepts that helped memory management evolve.  

### Types of Memory Allocation Schemes
- Single User Contiguous Scheme
- Fixed Partitions
- Dynamic Partitions
- Relocatable Dynamic Partitions

### Single-User Contiguous Scheme
- Commercially available in 1940s and 1950s
- Each program was loaded in its entirety into memory and allocated as much contiguous memory space allocated as it needed.
	- If the program was too large and didn’t fit the available memory space, it couldn’t be executed,
- Although early computers were physically large, they had very little memory.
- Computers have only a finite amount of memory. 
- If a program doesn’t fit, then either the size of the main memory must be increased or the program must be modified.
	- Making it smaller
	- Using methods that allow program segments (partitions made to the program) to be overlaid.
		- Transfer segments of a program from secondary storage into main memory for execution
		- Two or more segments take turns occupying the same memory locations.
- How it works:
	- Job/program is loaded (entirety), into memory & is allocated as much contiguous space in memory as it needs.
		- If program fits
			- Execute
		- Else
			- End 
- If a program doesn’t fit, then either the size of main memory must be increased, or the program must be modified to fit.
- ![](../res/Pasted%20image%2020250210231217.png)
- It is a non-networked environment allocate to each user, access to all available main memory for each job, and jobs are processed sequentially, one after the other.
	- To allocate memory, Memory Manager will:
		1. Evaluate the incoming job for its size whether it fits the memory space or not.
			- If it is, load into memory; if not, reject it and evaluate the next coming process.
		2. Monitor the occupied memory space. When the resident job ends its execution and no longer needs to be in memory, indicate that the entire amount of main memory space is now available and return to Step 1, evaluating the next incoming job.
- Major problem:
	- It doesn’t support multiprogramming (multiple jobs or processes occupying memory at the same time)

### Algorithm
1. Store first memory location of program into base register (for memory protection)
2. Set program counter (it keeps track of memory space used by the program) equal to address of first memory location
3. Read first instruction of program
4. Increment program counter by number of bytes in instruction
5. Has the last instruction been reached?
	- If yes, then stop loading program
	- If no, then continue with Step 6
6. Is program counter greater than memory size?
	- If yes, then stop loading program
	- If no, then continue with Step 7
7. Load instruction in memory
8. Read next instruction of program
9. Go to Step 4

### Disadvantages
- There is no support for multiprogramming or networking
- It can handle only one job at a time.
- This configuration was first used in research institutions but proved unacceptable for the business community.
- It was not cost effective to spend almost $200,000 for equipment that could be used by only one person at a time.

### In conclusion..
- The amount of work performed by the Memory Manager is minimal.
- Only two hardware items are needed: 
	- A register to store the base address 
	- An accumulator to keep track of the size of the program as it’s being read into memory.
- Once the program is entirely loaded into memory, it remains there until execution is complete, either through normal termination or by intervention of the OS.

### Fixed Partitions
- The first attempt to follow multiprogramming used fixed partitions (static partitions) within main memory.
	- One partition for each job.
- The size of each partition was designated when the system was powered on.
	- Each partition could only be reconfigured when the system was shut down.
	- Once the system was in operation, the partition sizes remained static.
- Introduced protection of the job’s memory space
	- Once a partition was assigned to a job, no other job could be allowed to enter its boundaries, either accidentally or intentionally.
		- Not a problem in single-user contiguous allocation schemes.
- Fixed Partitions is more flexible than the Single-User scheme because it allows several programs to be in memory at the same time.
- Fixed Partitions still requires that the entire program be stored contiguously and in memory from the beginning to the end of its execution.
- In order to allocate memory spaces to jobs, the OS’s Memory Manager must keep a table which shows:
	- Each memory partition size
	- Its address
	- Its access restrictions
	- Its current status (free or busy)
- As each job terminates, the status of its memory partition is changed from busy to free so an incoming job can be assigned to that partition.
- Memory manager allocates memory space to jobs
	- Uses a table
	- ![](../res/Pasted%20image%2020250210231833.png)
- ![](../res/Pasted%20image%2020250210231910.png)
- Disadvantages
	- The Fixed Partition scheme works well if all the jobs run on the system are of the same size or if the sizes are known ahead of time and don’t vary between reconfiguration.
	- If the partition sizes are too small:
		- larger jobs will be rejected if they’re too big to fit into the largest partition.
		- Large jobs will wait if the large partitions are busy.
		- Large jobs may have a longer turnaround time as they wait for free partitions of sufficient size or may never run. 
	- If the partition sizes are too big, memory is wasted.
		- If a job does not occupy the entire partition, the unused memory in the partition will remain idle.
		- It can’t be given to another job because each partition is allocated to only one job at a time.
	- Partial usage of fixed partitions and the coinciding creation of unused spaces within the partition is called `internal fragmentation` and is a major drawback to the fixed partition memory allocation scheme.

### Dynamic Partitions
- With Dynamic Partitions available memory is still kept in contiguous blocks but jobs are given only as much memory as they request when they are loaded for processing.
- A dynamic partition scheme fully utilizes memory when the first jobs are loaded.
- As new jobs enter the system that are not the same size as those that just vacated memory, they are fit into the available spaces on a priority basis.
	- First Come – First Serve priority
	- The subsequent allocation of memory creates fragments of free memory between blocks of allocated memory.
		- External fragmentation
	- Lets memory go to waste
- ![](../res/Pasted%20image%2020250210232903.png)

### Best-Fit Versus First-Fit Allocation
- For both fixed and dynamic memory allocation schemes, the OS must keep lists of each memory location noting which are free and which are busy.
- As new jobs come into the system, the free partitions must be allocated.
- These partitions may be allocated on the basis of:
	- First-fit memory allocation: 
		- First partition fitting the requirements
	- Best-fit memory allocation: 
		- Smallest partition fitting the requirements
		- Least wasted space

### Best-Fit Versus First-Fit Allocation
- For both schemes, the Memory Manager organizes the memory lists of the free and used partitions either by size or by location.
	- The Best-fit allocation method keeps the free/busy lists in order by size, smallest to largest.
		- Makes the best use of memory space.
	- The first-fit method keeps the free/bust list organized by memory locations, low-order memory to high-order memory.
		- Faster in making the allocation.
- ![](../res/Pasted%20image%2020250210233121.png)
- ![](../res/Pasted%20image%2020250210233158.png)
- Algorithm for first-fit
	- Assumes memory manager keeps two lists
		- One for free memory blocks
		- One for busy memory blocks
	- The operation consists of a simple loop that compares the size of each job to the size of each memory block until a block is found that is large enough to fit the job.
	- The job is stored into that block of memory and the Memory Manager moves out of the loop to fetch the next job from the entry queue
	- If the entire list is searched in vain, then the job is placed into a waiting queue.
	- The Memory Manager then fetches the next job and  repeats the process.
	- ![](../res/Pasted%20image%2020250210233329.png)
	- The goal is to find the smallest memory block into which the job will fit
	- The entire table must be searched before the allocation can be made because the memory blocks are physically stored in sequence according to their location in memory. 
	- ![](../res/Pasted%20image%2020250210233432.png)

- Hypothetical allocation schemes
	- Next-fit:
		- Starts searching from last allocated block, for next available block when a new job arrives
	- Worst-fit: 
		- Allocates largest free available block to new job
		- Opposite of best-fit
		- Good way to explore theory of memory allocation
		- Not best choice for an actual system

### Deallocation
- There eventually comes a time when memory space must be released or `deallocated`.
- For a fixed-partition system:
	- When the job is completed, the Memory Manager resets the status of the memory block where the job was stored to “free”. 
	- Any code may be used.
		- Example code: binary values with zero indicating free and one indicating busy.
- For dynamic-partition system: 
	- A more complex Algorithm is used because the algorithm tries to combine free areas of memory whenever possible.
	- The system  must be prepared for three alternative solutions:
		- Case 1: When the block to be deallocated is adjacent to another free block
		- Case 2: When the block to be deallocated is between two free blocks
		- Case 3: When the block to be deallocated is isolated from other free blocks
	- Case 1: Joining Two Free Blocks
		- Using the deallocation algorithm, the system sees that the memory to be released is next to a free memory block (Location 7800).
		- The List must be changed changes to reflect the  starting address of the new free block (7600) which was the address of the first instruction of the job that just released this block.
		- In addition, the memory block size for this new free space must be changed to show its new size, which is the combined total of the two free partitions (200 + 5).
		- ![](../res/Pasted%20image%2020250210233729.png)
		- ![](../res/Pasted%20image%2020250210233736.png)
	- Case 2: Joining Three Free Blocks
		- When the deallocated memory space is between two free memory blocks:
		- Using the deallocation algorithm, the system learns that the memory to be deallocated is between two free blocks of memory.
		- The sizes of the three free partitions (20 + 20 +205) must be combined and the total stored with the smallest beginning address, 7560.
		- Because the entry at location 7600 has been combined with the previous entry, we must empty out this entry.
			- We do that by changing the status to null entry, with no beginning address and no memory block size as indicated by an asterisk.
			- This negates the need to rearrange the list at the expense of memory.  
		- ![](../res/Pasted%20image%2020250210233831.png)
		- ![](../res/Pasted%20image%2020250210233838.png)
	- Case 3: Deallocating an Isolated Block
		- The third alternative is when the space to be deallocated is isolated from all other free areas.
			- Using the deallocation algorithm, the system learns that the memory block to be released is not adjacent to any free blocks of memory
			- It is between two other busy areas
			- The system must search the table for a null entry.
			- When the null entry is found:
				- The beginning memory location of the terminating job is entered in the beginning address column.
				- The job size is entered under the memory block size column
				- The status is changed from a null entry to free to indicate that a new block of memory is available.
		- ![](../res/Pasted%20image%2020250210233952.png)
		- ![](../res/Pasted%20image%2020250210234008.png)
		- ![](../res/Pasted%20image%2020250210234016.png)
		- ![](../res/Pasted%20image%2020250210234025.png)

### Relocatable Dynamic Partitions
- Both the fixed and dynamic memory allocation schemes described thus far shared some unacceptable fragmentation characteristics that had to be resolved before the number of jobs waiting to be accepted became unwieldy.
- In addition, there was a growing need to use all the slivers of memory often left over.
- The solution to both problems was the development of relocatable dynamic partitions.
- `Relocatable Dynamic Partitions` 
	- The Memory Manager relocates programs to gather together all of the empty blocks and compact them to make one block of memory large enough to accommodate some or all of the jobs waiting to get in.
- The `compaction` of memory is performed by the OS to reclaim fragmented sections of the memory space.
	- Every program in memory must be relocated so they’re contiguous. 
- `The compaction of memory `
	- Every address, and every reference to an address, within each program must be adjusted to account for the program’s new location in memory.
	- All other values within the program must be left alone.
- ![](../res/Pasted%20image%2020250210234212.png)
- ![](../res/Pasted%20image%2020250210234219.png)
- ![](../res/Pasted%20image%2020250210234225.png)
- ![](../res/Pasted%20image%2020250210234230.png)
- Compaction Issues:
	- What goes on behind the scenes when relocation and compaction take place?
	- What keeps track of how far each job has moved from its original storage area?
	- What lists have to be updated?
- What lists have to be updated?
	- After relocation and compaction, both the free list and the busy list are updated. 
		- Free list is changed to show the partition for the new block of free memory
			- The one formed as a result of compaction that will be located in memory starting after the last location used by the last job.
		- Busy list is changed to show the new locations for all of the jobs already in process that were relocated.
		- Special-purpose registers used for relocation:
			- Bounds register 
				- Used to store the highest (or lowest) location in memory accessible by each program.
				- This ensures that, during execution, a program won’t try to access memory locations that don’t belong to it.
			- Relocation register
				- Contains the value that must be added to each address referenced in the program so that the system  will be able to access the correct memory addresses after relocation.
				 - If the program isn’t relocated, the value, “zero”  is stored in the program’s relocation register.
- By compacting and relocating, the Memory Manager optimizes use of memory and, thus, Improves throughput.
- An unfortunate side effect is that more overhead is incurred than with the two previous memory allocation schemes.
- The crucial factor is the timing of the compaction.
	- When and how often should it be done.
- There are three options for the timing of compaction:
	- One approach is to do it when a certain percentage of memory becomes busy – 75%
		- The disadvantage of this approach is that the system would incur unnecessary overhead if no jobs were waiting to use the remaining 25%.
	- A second approach is to compact memory only when there are jobs waiting to get in.
		- This would entail constant checking of the entry queue, which might result in unnecessary overhead and slow down the processing of the jobs in the system.
- There are three options for the timing of compaction:
	- A third approach is to do it after a prescribed amount of time has elapsed.
		- If the amount of time chosen is too small, the system will spend more time on compaction than on processing.
		- If the amount of time is too large, too many jobs will congregate in the waiting queue and the advantages of compaction are lost. 
- There are three options for the timing of compaction:
	- The best choice for any system is decided by the OS designer who, based on the job mix and other factors, tries to optimize both processing time and memory use while keeping overhead as low as possible.

### Summary
- Four memory management techniques
	- Single-user systems
	- Fixed partitions
	- Dynamic partitions
	- Relocatable dynamic partitions
- Common requirements of four memory management techniques
	- Entire program loaded into memory
	- Contiguous storage
	- Memory residency until job completed





















































