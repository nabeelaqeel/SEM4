# Processor Management

### Definition of Terms
- `Process`: an active entity that requires a set of resources, including a processor and special registers, to perform its functions.  Also called a task.
- `Thread`: a portion of a process than can run independently.
- `Processor`: also known as the CPU.  Is the part of the machine that performs the calculations and executes the programs.

### Analogy 
- You buy a book shelf and want to put it together yourself.
- Once you get home, you take out the instruction manual and start to read the instructions on how to assemble the book shelf.
- The first step is to join part A to part B with a 5 cm screw, and you achieve it successfully.
- You move on to step 2.
- As you are about to execute step 3, you hear your little brother crying.  You quickly mark step 3 to indicate where you stop and go to check on your brother.
- You find that your brother fell down and injured his knee.
- You take out the first aid kit and start to bandage your brother’s knee.
- Once your brother has been taken care of, you go back to assembling your book shelf.
- Compare that to the OS.
- You are acting as the processor.
- There are 2 programs: assembling a book shelf (Job A) and bandaging your brother’s injury (Job B).
- When you are following the instructions to assemble the book shelf, each step you perform is a process.
- Your brother’s cry was an interrupt.
- When you left your book shelf to treat your brother, you left for a higher priority program.
- When you are interrupted, you perform a context switch by marking step 3 on the instruction so that you know where to continue later on.
- When you are treating your brother, each step you execute is a process.
 - When a job is completed, it is finished or terminated.

### Introduction 
- In a multiprogramming environment where there are many users and many jobs on the system, the processor must be allocated to each job fairly and efficiently.
- Multiprogramming requires that the processor be allocated to each job/process for a period of time and deallocated when the period expires.
- One processor can be shared by several jobs/processes if and only if the OS has a scheduling policy and scheduling algorithm to determine when to stop working on one job and proceed to another.
- In the analogy, you work on Job A until a higher priority job (Job B) came along.

### Job Scheduling vs. Process Scheduling
- The Processor Mgr is composed of 2 sub-managers:
- Job scheduler: in charge of job scheduling;
- Process scheduler: in charge of process scheduling.
- The scheduling of the two jobs (assemble a book shelf and bandage an injury) was on a first-come, first-served (FCFS) basis.
- Each job is initiated by the Job Scheduler based on certain criteria.
- Once a job is selected for execution, the Job Scheduler determines when each step (or set of steps) is executed (also based on certain criteria).
- When you started assembling the book shelf, each step in the assembly instructions is selected for execution by the Process Scheduler.
- Each job passes through a hierarchy of managers.
	- First, it encounters the Job Scheduler (high level scheduler).
- The Jobs Scheduler is only concerned with selecting jobs from a queue of incoming jobs and placing them in the process queue.
	- Goal: put jobs in a sequence that will use all of the system’s resources as fully as possible.

### Process Scheduler
- The Process Scheduler takes over after a job has been placed in the READY queue by the Job Scheduler.
- It is the low-level scheduler that assigns the CPU to execute the jobs placed in the queue.
- Determines which jobs get the CPU, when, and for how long.
- Other responsibilities:
	- Decides when a job should be interrupted;
	- Determines which queue a job should be moved to during its execution;
	- Determines a job has concluded and should be terminated.
- To schedule the CPU, the Process Scheduler takes advantage of a common trait among most programs: they alternate between CPU and I/O cycles.
- ![](../images/Pasted%20image%2020250211202555.png)
- The duration and frequency of CPU cycles vary from program to program but there are general tendencies that can be exploited when selecting a scheduling algorithm.
	- I/O bound jobs (e.g. printing a series of documents) have many brief CPU cycles and long I/O cycles.
	- CPU bound jobs (e.g. finding the first 300 prime numbers) have long CPU cycles and shorter I/O cycles.
- In a highly interactive environment, there is a third layer of Processor Mgr called the middle-level scheduler.
- When the system is overloaded, the middle-level scheduler removes active jobs from memory to reduce the degree of multi-programming and allows jobs to be completed faster.
	- Handles swapping out jobs and later swapping them back in.
- Job and Process Status
	- A job is in one of five states: HOLD to READY to RUNNING to WAITING and finally FINISHED.
- ![](../images/Pasted%20image%2020250211202658.png)
- 

| Transition          | Initiated by…                                                                                                                                     |
| ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |
| HOLD to READY       | Job Scheduler – checks availability of main memory and any requested devices.                                                                     |
| READY to RUNNING    | Process Scheduler – according to predefined algorithm, e.g. FCFS.                                                                                 |
| RUNNING to READY    | Process Scheduler – according to predefined time limit or criterion, e.g. policy interrupt.                                                       |
| RUNNING to WAITING  | Process Scheduler – initiated by an instruction in the job such as READ, WRITE, or other I/O rqt.                                                 |
| WAITING to READY    | Process Scheduler – initiated by a signal from the I/O Device Mgr that the I/O rqt has been satisfied.                                            |
| RUNNING to FINISHED | Process / Job Scheduler when (1) job has successfully completed, or (2) OS indicates an error has occurred and the job is terminated prematurely. |
- Process Control Block (PCB)
	- Each process is represented by a PCB.
	- PCB contains the basic info about the job – what it is, where it’s going, how much processing has been completed, where it is stored and how much it has spent in using resources.
- Content of each job’s Process Control Block
	- ![](../images/Pasted%20image%2020250211202831.png)
- A job’s PCB is created when the Job Scheduler accepts the job and is updated as the job progresses from beginning to termination.
- PCB contains all info required by the OS to manage the processing of the job.
- The progress of job execution is noted in PCB.
- ![](../images/Pasted%20image%2020250211202847.png)

### Process Scheduling Policy
- In a multiprogramming environment, there are usually more jobs that can be run at one time.
- In order to schedule jobs, the OS need to resolve 3 limitations:
	- There are a finite number of resources (e.g. disk drive, printers);
	- Certain resources, once allocated, cannot be shared (e.g. printer);
	- Certain resources require operator intervention (e.g. tape drives).
- What is a good process scheduling policy?
	- Maximize throughput.
	- Minimize response time.
	- Minimize turnaround time.
	- Minimize waiting time.
	- Maximize CPU efficiency.
	- Ensure fairness for all jobs.
- One criteria may contradict another.
- How do we choose a good scheduling policy?
- System designer must determine which criteria are most important for the specific system.
	- Example: the objective is to maximize CPU utilization while minimizing response time and balancing the use of all system components through a mix of I/O-bound and CPU-bound jobs. 

### Process Scheduling Algorithm
- The process scheduler relies on a process scheduling algorithm to allocate the CPU and move jobs through the system.
- 6 process scheduling algorithms:
	- First-Come, First Served (FCFS)	
		- Is a non-preemptive scheduling algorithm that handles jobs according to their arrival time.
		- Very simple; implemented using FIFO queue.
		- Good for batch systems, but unacceptable for interactive systems because users expect a quick response time.
		- When a job enters the system, its PCB is lined to the end of the READY queue and is removed when the processor becomes available.
		- Timeline for job sequence A, B C using FCFS algorithm.
			- ![](../images/Pasted%20image%2020250211203136.png)
			- If A, B and C arrive almost simultaneously, the turnaround time for Job A is 15, for Job B is 17 and for Job C is 18.  The average turnaround time is:
			- $(15 + 17 + 18)/3$ = 16.67
			- ![](../images/Pasted%20image%2020250211203235.png)
			- If the jobs arrive in a different order, say, C, B and A, the turnaround time for Job A is 18, for Job B is 3 and for Job C is 1.  The average turnaround time is:
			- $(18 + 3 + 1)/3$ = 7.3
		- Disadvantage of FCFS: the average turnaround time vary widely and are seldom minimized.

	- Shortest Job Next (SJN)
		- Is a non-preemptive scheduling algorithm.
		- Also known as Shortest Job First (SJF).
		- Handles jobs based on the length of their CPU cycle time.
		- Easiest to implement in batch environments where the estimated CPU time required is stated by the user at the start of a job.
		- Job:		A     B     C     D
		- CPU cycle:	5      2     6     4
		- ![](../images/Pasted%20image%2020250211203525.png)
		- The average turnaround time = $$\frac{2 + 6 + 11 + 17}{3} = 9.0$$
		- The average is actually:$$\frac{(2) + (4+2) + (5+4+2) + (6+5+4+2)}{3}= \frac{4*2 + 3*4 + 2*5 + 1*6}{4} = 9.0$$
		

		- The formula: $$\frac{t1(n) + t2(n-1) + t3(n-2) + … + tn(1)}{n}$$
		- SJN is optimal only when all jobs are available at the same time and CPU estimates are available and accurate.


	- Priority Scheduling
		- Is a non-preemptive algorithm.
		- One of the most common algorithms for batch systems.
		- It gives preferential treatment to important jobs.
		- Allows programs with the highest priority to be processed first, and they are not interrupted until their CPU cycles are completed or a natural wait occurs.
		- Priorities are assigned by a system administrator using characteristics extrinsic to the jobs.
			- Example: assigned based on the position of the user (lecturers first, then research assistants, then students).
		- In a commercial environment, users can purchase higher priority to guarantee their jobs are processed the fastest.
		- Priorities can also be determined by the Process Mgr based on intrinsic characteristics such as:
			- Memory requirements;
			- Number and type of peripheral devices;
			- Total CPU time;
			- Amount of time already spent in the system.

	- Shortest Remaining Time (SRT)
		- Is a preemptive version of SJN.
		- The processor is allocated to the job closest to completion.
		- An executing job can be preempted if a newer job in the READY queue has a shorter completion time.
		- Cannot be implemented in an interactive system because it requires advance knowledge of CPU time required.
		- Incurs more overhead than SJN because the OS has to monitor the CPU time for all jobs in the READY queue and must perform context switching for the jobs being swapped at preemption time.
		- ![](../images/Pasted%20image%2020250211205158.png)
		- Average turnaround time = $$\frac{14 + 4 + 1 + 6}{4} = 6.25$$
		- ![](../images/Pasted%20image%2020250211205305.png)
		- Compare the same job problem using SJN policy.
			- ![](../images/Pasted%20image%2020250211205318.png)
			- ![](../images/Pasted%20image%2020250211205731.png)
			- Average turnaround time = $$\frac{6 + 9 + 5 + 11}{4} = 7.75$$
		- SRT is faster than SJN – neglecting context switching that is required for preemptive algorithms.
			- When Job A is preempted, all of its processing info must be saved in its PCB for later when its execution is continued.
			- The content of Job B’s PCB are loaded into the registers so it can start running again.
		- Context switching still takes CPU time and may diminish the advantages of SRT.


	- Round Robin
		- Is a preemptive process scheduling algorithm that is used extensively in interactive systems.
		- Is not based on job characteristics.
		- A pre-determined slice of time is given to each job to ensure that the CPU is shared among all active processes and no job monopolizes the CPU.
		- A time slice is called a time quantum that varies between 100 ms to 1 or 2 second.
		- Jobs are placed in the READY queue using a FCFS scheme. 
		- The Process Scheduler:
			- selects the first job from the front of the queue, 
			- sets the timer to the time quantum, and
			- allocates the CPU to this job.
		- If the job has not finished executing when the time expires, the job is preempted and put at the end of the READY queue and its info is saved in its PCB.
		- If the job’s CPU cycles is shorter than the time quantum, either:
			- if this is the job’s last CPU cycle and it is finished, all resources allocated to it are released and the completed job is returned to the user; or
			- if the CPU cycle has been interrupted by an I/O request, the info about the job is saved in its PCB and it is linked at the end of the appropriate I/O queue.  Later, it is returned to the READY queue.
			- ![](../images/Pasted%20image%2020250211210737.png)
			- ![](../images/Pasted%20image%2020250211210753.png)
			- Average turnaround time = $$\frac{20 + 7 + 24 + 22}{4} = 18.25$$
			- Its efficiency depends on the size of the time quantum in relation to the average CPU time.
				- If the quantum is too large, it becomes the FCFS scheme.
				- If it is too small, the amount of context switching slows down job execution and increases the overhead dramatically.
			- ![](../images/Pasted%20image%2020250211210906.png)
			- What is the best quantum size?
				- It depends on the system.
			- Rules of thumb:
				- It should be long enough to allow 80% of the CPU cycles to run to completion.
				- It should be at least 100 times longer than the time required to perform one context switch.
	- Multi-Level Queues
		- Is not a separate scheduling algorithm.
		- It works in conjunction with other schemes.
		- Examples of multi-level queues:
			- A priority-based system with different queues for each priority level.
			- A system with one queue for CPU-bound jobs and another for I/O-bound jobs.  The Process Scheduler alternate between the two queues.
		- Examples (cont.)
			- In an environment that supports batch and interactive jobs, the batch jobs are put in one queue called the background queue while interactive jobs are put in a foreground queue and given priority over the background queue.
		- Issues:
			- Is the processor allocated to jobs in the first queue until it is empty before moving to the next queue or does it travel from queue to queue?
			- Is this fair to those who have earned or paid for a higher priority?
			- Is it fair to a low priority queue?
			- Can jobs in a lower priority queue move to a higher priority queue?
		- Case 1: No movement between queues
			- A very simple policy.
			- The CPU is allocated to jobs in the high-priority queue using FCFS and it allocated to jobs in lower priority queues only when higher-priority queues are empty.
		- Case 2: Movement between queues
			- The policy adjusts the priorities assigned to each job.
			- High-priority jobs are treated like all other once they are in the system.
			- When a time quantum expires, the job is preempted and moved to the end of the next lower queue.
			- A job’s priority may also be increased, e.g. when it issues an I/O request before its time quantum expires.
		- Case 3: Variable time quantum per queue
			- Is a variation of the movement btwn queues policy.
			- Allows for faster turnaround of CPU-bound jobs.
			- Each queue is given a time quantum twice as long as the previous queue.
				- The highest queue may have a time quantum of 100 ms, the second-highest queue has a time quantum of 200 ms and so on.
			- If a job does not finish its CPU cycle in the first quantum, it is moved to the end of the next lower level queue and when the processor is next allocated to it, it executes twice as long as before.
		- Case 4: Aging
			- Ensures that jobs in the lower-level queues will eventually complete their execution.
			- The OS keeps track of each job’s waiting time and when a job gets too old (reaches a certain time limit), it is moved to the next highest queue and so on until it reaches the top queue.
			- Guards against indefinite postponement that leads to starvation.































